---
title: "Assignment"
author: "Divij"
date: "5/29/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Loading the Data

```{r}
library(caret)
library(rattle)
library(rpart)
training<-read.csv("C:/Users/divij.a/Desktop/RPractice/8MachineLearning/pml-training.csv")
testing<-read.csv("C:/Users/divij.a/Desktop/RPractice/8MachineLearning/pml-testing.csv")
```

# Cleaning the data

Removing columns with mostly zeros.
```{r}
training<-training[,-grep("kurtosis+",names(training))]
testing<-testing[,-grep("kurtosis+",names(testing))]
training<-training[,-grep("skewness+",names(training))]
testing<-testing[,-grep("skewness+",names(testing))]
training<-training[,-grep("amplitude+",names(training))]
testing<-testing[,-grep("amplitude+",names(testing))]
training<-training[,-grep("^var+",names(training))]
testing<-testing[,-grep("^var+",names(testing))]
training<-training[,-grep("^stddev+",names(training))]
testing<-testing[,-grep("^stddev+",names(testing))]
training<-training[,-grep("^avg+",names(training))]
testing<-testing[,-grep("^avg+",names(testing))]
training<-training[,-grep("^max+",names(training))]
testing<-testing[,-grep("^max+",names(testing))]
training<-training[,-grep("^min+",names(training))]
testing<-testing[,-grep("^min+",names(testing))]
```


Removing columns which are not related

```{r}
training<-training[,-(1:8)]
testing<-testing[,-(1:8)]
```


# Data Partitioning

Used for cross validation
```{r}
inTrain<-createDataPartition(y=training$classe,p=0.6,list=FALSE)
training2<-training[inTrain,]
testing2<-training[-inTrain,]
```

# Model 1- decision tree(rpart)

```{r cache=TRUE}
modrpart<-train(classe~.,method="rpart",data=training2)
predrpart<-predict(modrpart,testing2)
fancyRpartPlot(modrpart$finalModel)
confusionMatrix(testing2$classe,predrpart)
```

As seen above, the accuracy obtained is very low, around 50%.

# Model 2- Random forests

```{r cache=TRUE }
modrf<-train(classe~.,method="rf",data=training2)
predrf<-predict(modrf,testing2)
confusionMatrix(testing2$classe,predrf)
```

As seen, the accuracy obtained is quite high, 99%.


# Conclusion

Random forest performs much better, with a much higher accuracy rate.

The predictions for the given test set are:

```{r}
pred<-predict(modrf,testing)
pred
```{r}
